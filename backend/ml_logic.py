"""
QCaaS ML Logic - ULTRA OPTIMIZED WITH FIX
Fixes: VQC Sampler register size error
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Qiskit imports
from qiskit.primitives import Sampler
from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes
from qiskit_machine_learning.algorithms import VQC
from qiskit.algorithms.optimizers import COBYLA

# ‚ö° SPEED OPTIMIZATIONS
NUM_QUBITS = 2
TEST_SIZE = 0.25
RANDOM_STATE = 42
VQC_REPS = 1
VQC_MAXITER = 50


def run_comparison_pipeline(dataset_name):
    """Main pipeline"""
    print(f"\n{'='*70}")
    print(f"STARTING: {dataset_name.upper()}")
    print(f"{'='*70}")
    
    X, y = _load_and_prepare_data(dataset_name)
    
    print(f"\n{'='*70}")
    print("PHASE 1: SVM")
    print(f"{'='*70}")
    svm_metrics = _run_svm(X, y)
    
    print(f"\n{'='*70}")
    print("PHASE 2: VQC")
    print(f"{'='*70}")
    vqc_metrics = _run_vqc(X, y)
    
    return svm_metrics, vqc_metrics


def _load_and_prepare_data(dataset_name):
    """Load CSV - optimized"""
    dataset_config = {
        'iris': {'file': 'iris.csv', 'target': 'Species', 'drop': ['Id']},
        'heart': {'file': 'heart.csv', 'target': 'num', 'drop': ['id']},
        'diabetes': {'file': 'diabetes.csv', 'target': 'Outcome', 'drop': []},
        'stroke': {'file': 'stroke.csv', 'target': 'stroke', 'drop': ['id']},
        'water_potability': {'file': 'water_potability.csv', 'target': 'Potability', 'drop': []}
    }
    
    if dataset_name not in dataset_config:
        raise ValueError(f"Unknown dataset: {dataset_name}")
    
    config = dataset_config[dataset_name]
    filepath = f'data/{config["file"]}'
    
    df = pd.read_csv(filepath, low_memory=False)
    print(f"[OK] Loaded {len(df)} rows")
    
    if config['drop']:
        df.drop(columns=config['drop'], errors='ignore', inplace=True)
    
    if config['target'] not in df.columns:
        raise ValueError(f"Target '{config['target']}' not found")
    
    y = df[config['target']].copy()
    X_df = df.drop(columns=[config['target']])
    
    X_df.fillna(X_df.median(numeric_only=True), inplace=True)
    X_df.fillna('Unknown', inplace=True)
    
    valid_mask = y.notna()
    y = y[valid_mask]
    X_df = X_df[valid_mask]
    
    categorical_cols = X_df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        X_df[col] = LabelEncoder().fit_transform(X_df[col].astype(str))
    
    X = X_df.values.astype(np.float64)
    
    if y.dtype == object:
        y = LabelEncoder().fit_transform(y.astype(str))
    else:
        y = y.values.astype(np.int64)
        if dataset_name == 'heart':
            y = (y > 0).astype(np.int64)
    
    if np.isnan(X).any():
        col_median = np.nanmedian(X, axis=0)
        inds = np.where(np.isnan(X))
        X[inds] = np.take(col_median, inds[1])
    
    print(f"Samples: {X.shape[0]} | Features: {X.shape[1]} | Classes: {len(np.unique(y))}")
    return X, y


def _calculate_metrics(y_true, y_pred):
    """Calculate metrics"""
    return {
        'accuracy': round(float(accuracy_score(y_true, y_pred)), 4),
        'precision': round(float(precision_score(y_true, y_pred, average='weighted', zero_division=0)), 4),
        'recall': round(float(recall_score(y_true, y_pred, average='weighted', zero_division=0)), 4),
        'f1_score': round(float(f1_score(y_true, y_pred, average='weighted', zero_division=0)), 4)
    }


def _run_svm(X_original, y):
    """Train SVM"""
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_original)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
    )
    
    print(f"Training SVM on {len(X_train)} samples...")
    svm = SVC(kernel='rbf', random_state=RANDOM_STATE)
    svm.fit(X_train, y_train)
    
    y_pred = svm.predict(X_test)
    metrics = _calculate_metrics(y_test, y_pred)
    
    print(f"‚úì Accuracy: {metrics['accuracy']:.4f}")
    return metrics


def _run_vqc(X_original, y):
    """
    Train VQC - FIXED VERSION
    Fix: Properly initialize VQC with correct parameter order
    """
    print(f"Preprocessing for VQC...")
    
    # PCA to NUM_QUBITS features
    pca = PCA(n_components=NUM_QUBITS)
    X_reduced = pca.fit_transform(X_original)
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_reduced)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
    )
    
    print(f"Configuring {NUM_QUBITS}-qubit quantum circuit...")
    
    # ‚úÖ FIX: Explicitly specify num_qubits parameter
    feature_map = ZZFeatureMap(
        feature_dimension=NUM_QUBITS,
        reps=VQC_REPS,
        entanglement='linear',
        insert_barriers=False
    )
    
    ansatz = RealAmplitudes(
        num_qubits=NUM_QUBITS,
        reps=VQC_REPS,
        entanglement='linear',
        insert_barriers=False
    )
    
    # ‚úÖ FIX: Create sampler without options
    sampler = Sampler()
    
    optimizer = COBYLA(maxiter=VQC_MAXITER)
    
    # ‚úÖ FIX: Initialize VQC with explicit parameters
    try:
        vqc = VQC(
            sampler=sampler,
            feature_map=feature_map,
            ansatz=ansatz,
            optimizer=optimizer,
            callback=None
        )
        
        print(f"‚öõÔ∏è  Training VQC (60-90 seconds)...")
        vqc.fit(X_train, y_train)
        
        print(f"üîÆ Making predictions...")
        y_pred = vqc.predict(X_test)
        
    except Exception as e:
        error_msg = str(e)
        print(f"‚ö†Ô∏è  VQC error: {error_msg[:100]}")
        
        # ‚úÖ FALLBACK: Use even simpler configuration
        if "Register size" in error_msg or "integer" in error_msg.lower():
            print(f"[FALLBACK] Using simplified 1-qubit VQC...")
            
            # Reduce to 1 qubit
            pca_fb = PCA(n_components=1)
            X_reduced_fb = pca_fb.fit_transform(X_original)
            X_scaled_fb = StandardScaler().fit_transform(X_reduced_fb)
            X_train_fb, X_test_fb, _, _ = train_test_split(
                X_scaled_fb, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
            )
            
            feature_map_fb = ZZFeatureMap(1, reps=1, entanglement='linear', insert_barriers=False)
            ansatz_fb = RealAmplitudes(1, reps=1, entanglement='linear', insert_barriers=False)
            optimizer_fb = COBYLA(maxiter=25)
            
            vqc = VQC(
                sampler=Sampler(),
                feature_map=feature_map_fb,
                ansatz=ansatz_fb,
                optimizer=optimizer_fb
            )
            
            vqc.fit(X_train_fb, y_train)
            y_pred = vqc.predict(X_test_fb)
            
        else:
            # Re-raise if it's a different error
            raise e
    
    metrics = _calculate_metrics(y_test, y_pred)
    print(f"‚öõÔ∏è  Accuracy: {metrics['accuracy']:.4f}")
    
    return metrics
